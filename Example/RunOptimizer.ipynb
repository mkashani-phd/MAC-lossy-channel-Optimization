{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import src.TagModel as model\n",
    "import src.TagModel_lat as model_latency\n",
    "import src.Auth as Auth\n",
    "import utils.utils as utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Model\n",
    "\n",
    "Just considering the E[A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 21600\n",
      "Gurobi Optimizer version 11.0.2 build v11.0.2rc0 (mac64[arm] - Darwin 23.4.0 23E224)\n",
      "\n",
      "CPU model: Apple M3\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 27990 rows, 28816 columns and 85095 nonzeros\n",
      "Model fingerprint: 0x7ddbe091\n",
      "Variable types: 13951 continuous, 14865 integer (14865 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 3e+01]\n",
      "  Objective range  [4e-02, 9e-01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 14400 rows and 14415 columns\n",
      "Presolve time: 0.05s\n",
      "Presolved: 13590 rows, 14401 columns, 55830 nonzeros\n",
      "Variable types: 1 continuous, 14400 integer (14400 binary)\n",
      "\n",
      "Root relaxation: objective 1.948696e+03, 14266 iterations, 0.27 seconds (0.95 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1948.69592    0 13050   -0.00000 1948.69592      -     -    0s\n",
      "H    0     0                      19.0760212 1948.69592      -     -    0s\n",
      "H    0     0                      20.1680733  366.24394  1716%     -    1s\n",
      "     0     0  366.24394    0 2556   20.16807  366.24394  1716%     -    1s\n",
      "     0     0  362.28856    0 3047   20.16807  362.28856  1696%     -    3s\n",
      "     0     0  361.03651    0 3048   20.16807  361.03651  1690%     -    4s\n",
      "     0     0  354.86081    0 2890   20.16807  354.86081  1660%     -    4s\n",
      "     0     0  353.27486    0 2876   20.16807  353.27486  1652%     -    4s\n",
      "     0     0  351.39875    0 2911   20.16807  351.39875  1642%     -    4s\n",
      "     0     0  351.25591    0 2952   20.16807  351.25591  1642%     -    4s\n",
      "H    0     0                      20.6408306  329.76139  1498%     -    5s\n",
      "     0     0  329.76139    0 2727   20.64083  329.76139  1498%     -    5s\n",
      "     0     0  299.22828    0 3145   20.64083  299.22828  1350%     -   10s\n",
      "H    0     0                      21.0516739  280.92695  1234%     -   12s\n",
      "     0     0  280.92695    0 3420   21.05167  280.92695  1234%     -   12s\n",
      "     0     0  279.96220    0 3382   21.05167  279.96220  1230%     -   13s\n",
      "     0     0  277.19565    0 3338   21.05167  277.19565  1217%     -   15s\n",
      "     0     0  271.51871    0 3691   21.05167  271.51871  1190%     -   16s\n",
      "     0     0  270.52562    0 3742   21.05167  270.52562  1185%     -   17s\n",
      "     0     0  270.23391    0 3546   21.05167  270.23391  1184%     -   17s\n",
      "     0     0  270.22180    0 3546   21.05167  270.22180  1184%     -   17s\n",
      "     0     2  270.17646    0 3546   21.05167  270.17646  1183%     -   21s\n",
      "     3     8  250.90804    2 3013   21.05167  267.12257  1169%  2911   25s\n",
      "    15    24  224.53128    4 2858   21.05167  250.00182  1088%  4849   31s\n",
      "    23    32  236.61847    4 2972   21.05167  249.98108  1087%  4511   35s\n",
      "H   32    40                      28.0081374  237.71339   749%  4772   37s\n",
      "    56    66  220.50833    7 2341   28.00814  236.61544   745%  3208   40s\n",
      "H   65    77                      28.4808948  236.61544   731%  2935   41s\n",
      "   106   116  207.09938   10 1771   28.48089  236.61544   731%  2142   45s\n",
      "   181   198  168.50798   15 1256   28.48089  236.61544   731%  1550   52s\n",
      "   277   319  129.67469   20  913   28.48089  236.61544   731%  1229   55s\n",
      "   682   765   44.20894   59  125   28.48089  236.61544   731%   586   62s\n",
      "   937   935  217.54676    6 2604   28.48089  234.79949   724%   467   66s\n",
      "  1030  1025  191.61341    8 2236   28.48089  234.79949   724%   467   70s\n",
      "  1317  1306  138.31300   21 1422   28.48089  234.79949   724%   420   75s\n",
      "  1563  1482  141.60274   21 3546   28.48089  234.79949   724%   387   95s\n",
      "  1566  1484  103.64409   36 2114   28.48089  152.04711   434%   386  106s\n",
      "  1579  1493   79.93655   17 1008   28.48089   79.93655   181%   383  110s\n",
      "H 1580  1418                      38.7420489   78.21583   102%   383  111s\n",
      "  1584  1421   64.60638   24 1096   38.74205   64.60638  66.8%   382  115s\n",
      "  1589  1424   52.42067   29 1063   38.74205   52.42067  35.3%   381  120s\n",
      "H 1589  1352                      44.1659357   52.42067  18.7%   381  121s\n",
      "  1592  1354   52.30177    5  948   44.16594   52.30177  18.4%   380  125s\n",
      "  1596  1357   52.30177   22  796   44.16594   52.30177  18.4%   379  130s\n",
      "H 1600  1291                      45.3281972   52.30177  15.4%   378  134s\n",
      "  1601  1291   52.30177   12   74   45.32820   52.30177  15.4%   378  135s\n",
      "  1604  1293   52.30177   32   78   45.32820   52.30177  15.4%   377  140s\n",
      "  1612  1300   45.32820   60  469   45.32820   52.30177  15.4%   455  146s\n",
      "  1613  1301   52.30177   17  595   45.32820   52.30177  15.4%   454  152s\n",
      "  1615  1302   52.30177   33  535   45.32820   52.30177  15.4%   454  161s\n",
      "  1617  1304   52.30177   58  592   45.32820   52.30177  15.4%   453  178s\n",
      "H 1617  1238                      46.4904668   52.30177  12.5%   453  179s\n",
      "  1619  1239   52.30177   39  689   46.49047   52.30177  12.5%   453  192s\n",
      "  1620  1240   46.49047   90 1232   46.49047   52.30177  12.5%   452  196s\n",
      "  1621  1240   52.30177    5  656   46.49047   52.30177  12.5%   452  214s\n",
      "  1622  1241   52.30177    7  948   46.49047   52.30177  12.5%   452  217s\n",
      "  1623  1242   52.30177   59  843   46.49047   52.30177  12.5%   452  370s\n",
      "  1625  1243   52.30177   38  787   46.49047   52.30177  12.5%   451  383s\n",
      "  1626  1244   46.49047   86  935   46.49047   52.30177  12.5%   451  385s\n",
      "  1627  1244   52.30177    8  852   46.49047   52.30177  12.5%   450  409s\n",
      "  1628  1245   52.30177   20 1077   46.49047   52.30177  12.5%   450  412s\n",
      "  1629  1246   52.30177   24 1063   46.49047   52.30177  12.5%   450  424s\n",
      "  1630  1246   52.30177    5  703   46.49047   52.30177  12.5%   450  448s\n",
      "  1631  1247   52.30177   11  703   46.49047   52.30177  12.5%   449  456s\n",
      "  1632  1251   52.30177   23  883   46.49047   52.30177  12.5%   880  475s\n",
      "  1634  1254   52.30177   24 1268   46.49047   52.30177  12.5%   889  495s\n",
      "  1638  1261   52.30177   25 1639   46.49047   52.30177  12.5%   925  520s\n",
      "  1646  1262   52.30177   26 1854   46.49047   52.30177  12.5%  1060  544s\n",
      "  1654  1267   52.30177   26 1792   46.49047   52.30177  12.5%  1182  557s\n",
      "  1670  1278   52.30177   27 1832   46.49047   52.30177  12.5%  1219  569s\n",
      "  1678  1278   52.30177   28 1848   46.49047   52.30177  12.5%  1219  573s\n",
      "  1693  1286   52.30177   29 1783   46.49047   52.30177  12.5%  1241  578s\n",
      "  1706  1290   52.30177   29 1752   46.49047   52.30177  12.5%  1242  590s\n",
      "  1727  1311   52.30177   30 1666   46.49047   52.30177  12.5%  1245  600s\n",
      "  1742  1314   52.30177   31 1673   46.49047   52.30177  12.5%  1245  607s\n",
      "  1750  1328   52.30177   31 1595   46.49047   52.30177  12.5%  1244  617s\n",
      "  1767  1346   52.30177   32 1558   46.49047   52.30177  12.5%  1238  629s\n",
      "  1790  1360   52.30177   33 1606   46.49047   52.30177  12.5%  1232  635s\n",
      "  1812  1384   52.30177   34 1589   46.49047   52.30177  12.5%  1225  640s\n",
      "  1843  1383   52.30177   35 1514   46.49047   52.30177  12.5%  1217  645s\n",
      "  1853  1419   52.30177   35 1465   46.49047   52.30177  12.5%  1213  652s\n",
      "  1892  1452   52.30177   36 1411   46.49047   52.30177  12.5%  1197  656s\n",
      "  1938  1495   52.30177   37 1456   46.49047   52.30177  12.5%  1177  665s\n",
      "  1996  1540   52.15982   39 1290   46.49047   52.30177  12.5%  1152  670s\n",
      "  2135  1653   50.99696   42 1123   46.49047   52.30177  12.5%  1093  677s\n",
      "  2222  1725   50.65847   43  983   46.49047   52.30177  12.5%  1055  680s\n",
      "  2436  1893     cutoff   49        46.49047   52.30177  12.5%   970  685s\n",
      "  2724  2078   47.99113   52  829   46.49047   52.30177  12.5%   874  694s\n",
      "  2881  2187   47.56503   53  702   46.49047   52.30177  12.5%   829  700s\n",
      "  3181  2351   47.19834   56  693   46.49047   52.30177  12.5%   757  706s\n",
      "  3354  2418   50.77041   39 1022   46.49047   52.30177  12.5%   723  712s\n",
      "  3530  2469   49.54814   41  972   46.49047   52.30177  12.5%   692  715s\n",
      "  3800  2528     cutoff   47        46.49047   52.30177  12.5%   656  723s\n",
      "  3880  2536   48.12785   56   80   46.49047   52.30177  12.5%   648  728s\n",
      "  3923  2543   48.12785   58   82   46.49047   52.30177  12.5%   648  736s\n",
      "  3962  2557   48.09924   64   91   46.49047   52.30177  12.5%   648  740s\n",
      "  3999  2592   48.12784   70   76   46.49047   52.30177  12.5%   649  746s\n",
      "  4046  2640   47.97503   76   88   46.49047   52.30177  12.5%   645  750s\n",
      "  4230  2758   48.05177   84   93   46.49047   52.30177  12.5%   628  758s\n",
      "* 4315  2569              95      47.8296900   52.30177  9.35%   623  764s\n",
      "  4369  2658   52.30177   31 1720   47.82969   52.30177  9.35%   622  767s\n",
      "  4480  2815   52.30177   32 1417   47.82969   52.30177  9.35%   615  773s\n",
      "  4689  2986 infeasible   34        47.82969   52.30177  9.35%   595  779s\n",
      "  4968  3049   52.30177   36 1254   47.82969   52.30177  9.35%   569  787s\n",
      "  5152  3119   52.30177   37 1195   47.82969   52.30177  9.35%   555  793s\n",
      "  5332  3198   51.66248   40 1348   47.82969   52.30177  9.35%   543  799s\n",
      "  5439  3282   48.50988   44  951   47.82969   52.30177  9.35%   540  806s\n",
      "  5586  3365   51.69875  131   70   47.82969   52.30177  9.35%   534  812s\n",
      "  5725  3517   52.30177   33 1513   47.82969   52.30177  9.35%   526  818s\n",
      "  5930  3658   52.30177   35 1321   47.82969   52.30177  9.35%   514  824s\n",
      "  6107  3864   52.30177   34 1388   47.82969   52.30177  9.35%   507  830s\n",
      "  6373  4007   52.30177   37 1122   47.82969   52.30177  9.35%   493  838s\n",
      "  6573  4185   52.30177   38 1081   47.82969   52.30177  9.35%   485  845s\n",
      "  6809  4344   50.13349   40  869   47.82969   52.30177  9.35%   476  853s\n",
      "  7059  4514   49.03036   42  976   47.82969   52.30177  9.35%   467  861s\n",
      "  7259  4739   48.16183   46  274   47.82969   52.30177  9.35%   461  870s\n",
      "  7598  4879   52.30177   39 1089   47.82969   52.30177  9.35%   451  878s\n",
      "  7788  5046   51.71292   40 1010   47.82969   52.30177  9.35%   449  887s\n",
      "  8060  5239   48.96553   49  667   47.82969   52.30177  9.35%   446  897s\n",
      "  8347  5679   51.48949   41  796   47.82969   52.30177  9.35%   442  909s\n",
      "  8889  6010   48.92310   54  236   47.82969   52.30177  9.35%   425  919s\n",
      "  9429  6399   52.30177   45  247   47.82969   52.30177  9.35%   414  932s\n",
      "  9933  6600   50.71102   45  649   47.82969   52.30177  9.35%   402  943s\n",
      " 10250  6879   50.22147   50  371   47.82969   52.30177  9.35%   399  956s\n",
      " 10656  7049   52.00363   49   76   47.82969   52.30177  9.35%   394  969s\n",
      " 10955  7262   49.33468   52  236   47.82969   52.30177  9.35%   396  981s\n",
      "*10964   661              50      52.3017736   52.30177  0.00%   396  981s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 360\n",
      "  Cover: 151\n",
      "  Implied bound: 9\n",
      "  MIR: 22\n",
      "  StrongCG: 82\n",
      "  Flow cover: 8\n",
      "  Zero half: 1\n",
      "  RLT: 607\n",
      "  BQP: 126\n",
      "\n",
      "Explored 11275 nodes (4477367 simplex iterations) in 981.44 seconds (2418.73 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 52.3018 47.8297 46.4905 ... 20.6408\n",
      "No other solutions better than 52.3018\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Warning: max constraint violation (1.0955e-06) exceeds tolerance\n",
      "Best objective 5.230177439362e+01, best bound 5.230177439362e+01, gap 0.0000%\n",
      "Status: 1\n",
      "Objective value: 4.0\n",
      "Experiment saved as experiment number 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': array([1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922,\n",
       "        1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922,\n",
       "        1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922,\n",
       "        1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922,\n",
       "        1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922, 1.7433922]),\n",
       " 'L': array([26, 22, 21, 21, 19, 19, 18, 18, 16, 15, 15, 12, 12, 10, 10,  8,  7,\n",
       "         8,  5,  5,  6,  3,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " 'average_A': 1.7433922005,\n",
       " 'average_L': 9.9,\n",
       " 'computation_(tag to message ratio)': 0.5,\n",
       " 'goodput_without_tag_adjustment': 0.8888888888888888,\n",
       " 'goodput_with_tag_adjustment': 0.9334548769371012,\n",
       " 'security_goodput': 0.9999999999999999,\n",
       " 'rows_that_breaks_the_verification': [3, 4, 8, 28]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "parameters = {'m_nr': 30, 't_nr': 15, \n",
    "              'p': 0.9, 'q': 1, \n",
    "              'TagEveryMessage': True, \n",
    "              'AtLeastOnce': False, \n",
    "              'EquivalentA': True}\n",
    "\n",
    "exp = utils.Run_Experiment(model        = model.math_model,\n",
    "                           parameters   = parameters,\n",
    "                           eval         = Auth.evaluate,\n",
    "                           m_size       = 1024,\n",
    "                           t_size       = 256,\n",
    "                           save         = True)\n",
    "exp['eval']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 1\n",
      "Objective value: 12.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': array([5.5132156 , 5.00063609, 4.57805658, 4.23647707, 3.96779756,\n",
       "        3.76472804, 3.62070753, 3.52983112, 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 , 3.4867844 ,\n",
       "        3.4867844 , 3.4867844 , 3.09936391, 2.71194342, 2.32452293,\n",
       "        1.93710245, 1.54968196, 1.16226147, 0.77484098, 0.38742049]),\n",
       " 'L': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'average_A': 3.4104847687200017,\n",
       " 'average_L': 0.0,\n",
       " 'computation_(tag to message ratio)': 1.0,\n",
       " 'goodput_without_tag_adjustment': 0.9411764705882353,\n",
       " 'goodput_with_tag_adjustment': 0.9317561419472248,\n",
       " 'security_goodput': 0.8526211921800004,\n",
       " 'rows_that_breaks_the_verification': [1,\n",
       "  8,\n",
       "  16,\n",
       "  25,\n",
       "  34,\n",
       "  43,\n",
       "  52,\n",
       "  61,\n",
       "  70,\n",
       "  79,\n",
       "  87,\n",
       "  94]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'m_nr': 100, 't_nr': 100,\n",
    "                'p': 0.9, 'q': 1,\n",
    "                'x': 4}\n",
    "exp = Auth.ProMAC_experiment(parameters=parameters, x = 9)\n",
    "Auth.evaluate(exp,m_size=1024,t_size=int(256/4), b = 256 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the optimizer With Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2025-06-06\n",
      "\n",
      "Interrupt request received\n",
      "Status: -1\n",
      "Objective value: 6.0\n",
      "Experiment saved as experiment number 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'A': array([1.44, 1.44, 1.92, 5.12, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64, 0.64,\n",
       "        1.44, 0.64, 0.64, 0.64, 0.64, 1.28, 0.64, 1.44, 0.64]),\n",
       " 'L': array([0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       " 'average_A': 1.1200000000000003,\n",
       " 'average_L': 0.45,\n",
       " 'computation_(tag to message ratio)': 1.0,\n",
       " 'goodput_without_tag_adjustment': 0.8,\n",
       " 'goodput_with_tag_adjustment': 0.8178913738019169,\n",
       " 'security_goodput': 0.6588235294117649,\n",
       " 'rows_that_breaks_the_verification': [1, 2, 3, 4, 17, 19]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'m_nr': 20, 't_nr': 20,\n",
    "                'p': 0.8, 'q': 1,\n",
    "                'TagEveryMessage': True,\n",
    "                'AtLeastOnce': False,\n",
    "                'EquivalentA': True,\n",
    "                'weight_A': 5,\n",
    "                'weight_L': .1}\n",
    "\n",
    "exp = utils.Run_Experiment(model = model_latency.math_model,\n",
    "                            parameters = parameters,\n",
    "                            eval=Auth.evaluate,\n",
    "                            save=True)\n",
    "exp['eval']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
